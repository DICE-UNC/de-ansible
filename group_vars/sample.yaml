global_config_dir: /etc/iplant
de_config_dir: "{{ global_config_dir }}/de"

remote_registry: discoenv

app_version_name: Phthalo
app_version: 2.2.0
de_version: "{{ app_version }}"
drop_number: 0

tomcat_http_port: 8080
tomcat_https_port: 8443
tomcat_admin_username: admin
tomcat_admin_password: blah
tomcat_user: tomcat
ansible_user: ansible

ssl_certificate_server_dir: /etc/iplant/ssl
#
ssl_cert_file: iplant.crt
ssl_key_file:  iplant.key
# should match file in cas/files playbook
cas_ssl_cert_file: server.crt
cas_ssl_key_file: server.key


# de ui settings
app_server_base_url: "https://some.server1.at.a.place"
app_server_hostname: "some.server1.at.a.place"
app_description: DFC Test Lab Discovery Environment
app_rpc_name: discoveryenvironment
app_empty_url: empty
app_context_menu_enabled: false
de_maintenance_file: de-maintenance
prod_deployment: false
de_notification_poll: 15

validate_certs: False

default_service_port: 60000

denyhosts_allowed:
  - 172.0.0.0/8
  - 152.54.0.0/16

# --- CAS properties --- #
cas_app_list: all iPlant applications
cas_base: http://some.server1.at.a.place:8443/cas
cas_context_path: cas
cas_do_ssl_config: true
cas_git_url:  https://github.com/DICE-UNC/DFC-CAS-overlay.git
cas_git_project_name: DFC-CAS-overlay
cas_group_attribute: entitlement
cas_no_logout_url: http://some.server1.at.a.place
# cas_port: 8080
cas_port: 8443
cas_tomcat_user: tomcat
cas_uid_domain:
# --- /CAS properties --- #

# --- LDAP properties --- #
ldap_port: 389
ldap_use_starttls: false
ldap_search_base_dn: ou=Users,dc=DFC,dc=unc,dc=edu
ldap_manager_dn: cn=Manager,dc=DFC,dc=unc,dc=edu
ldap_admin_password: blah
ldap_genadminpw: blah
ldap_password: blah
ldap_password_size: 8
ldap_host: localhost
ldap_slapd_dpkg_reconfigure_done: false
ldap_dpkg_reconfigure: false
ldap_global_user: root
ldap_global_use_sudo: false
ldap_include_create_user_and_groups: true
ldap_include_create_indexes: true
ldap_include_create_autofs: false
ldap_include_create_automount: false
ldap_include_create_sudo: false
ldap_include_create_sudo_master: false
ldap_include_testde: true

ldap_dc: dc=DFC,dc=unc,dc=edu
ldap_g_suffix: Groups
ldap_u_suffix: Users
ldap_m_suffix: Machines
ldap_tld: dfc

ldap_ansible_done_dir: /etc/ansible/.done
ldap_done_dir: "{{ldap_ansible_done_dir}}/ldap"

ldap_create_user_and_groups_done: "{{ldap_done_dir}}/create-users-and-groups"
ldap_create_indexes_done: "{{ldap_done_dir}}/create-indexes"
ldap_create_autofs_done: "{{ldap_done_dir}}/create-autofs"
ldap_create_automount_done: "{{ldap_done_dir}}/create-automount"
ldap_create_sudo_done: "{{ldap_done_dir}}/create-sudo"
ldap_create_sudo_master_done: "{{ldap_done_dir}}/create-sudo-master"
ldap_create_testde_done: "{{ldap_done_dir}}/create-testde"

ldap_slapd_dpkg_reconfigure_done: "{{ldap_done_dir}}/slapd-dpkg-reconfigure-done"


ldap_domain_name: some.server1.at.a.place
ldap_enable_ssl: false
ldap_country: US
ldap_state: North Carolina
ldap_location: Chapel Hill
ldap_organization: DFC

# --- /LDAP properties --- #

docker:
  log_driver: syslog
  tag: latest
  user: discoenv
  version: 1.9.1
  registry:
    port: 5000

facepalm_jar: https://github.com/DICE-UNC/de-ansible/blob/vmlab/downloads/facepalm/facepalm-standalone.jar?raw=true

java:
  version: 1.7.0

timezone: America/New_York

proxy_env:
  http_proxy: http://gateway.xx:8080/
  https_proxy: http://gateway.xx:8080/
  http_maven_proxy_port: 8080
  http_maven_proxy_host: gateway.xx

db_targz: https://everdene.iplantcollaborative.org/jenkins/job/databases-dev/lastSuccessfulBuild/artifact/databases/de-database-schema/database.tar.gz
jexdb_targz: https://everdene.iplantcollaborative.org/jenkins/job/databases-dev/lastSuccessfulBuild/artifact/databases/jex-db/jex-db.tar.gz
metadata_db_targz: https://everdene.iplantcollaborative.org/jenkins/job/databases-dev/lastSuccessfulBuild/artifact/databases/metadata/metadata-db.tar.gz
notification_db_targz: https://everdene.iplantcollaborative.org/jenkins/job/databases-dev/lastSuccessfulBuild/artifact/databases/notification-db/notification-db.tar.gz


net_dmz: 172.0.0.0/8
net_vpn: 172.0.0.0/8
net_trust: 152.54.0.0/16
net_campus: 152.54.0.0/16
net_wifi: 152.54.0.0/16

de_war_url_prefix: https://github.com/iPlantCollaborativeOpenSource/DiscoveryEnvironment/releases/download/1.9.4-RELEASE/
bg_war_url_prefix: "{{de_war_url_prefix}}"

services_host: some.server2.at.a.place
ui_host: some.server2.at.a.place
condor_host: some.server5.at.a.place
cas_host: some.server1.at.a.place

parasitic: false

iplant_yum_repo: http://everdene.iplantcollaborative.org/rpms/iplant-release.repo

agave_base_url: https://agave.iplantc.org
agave_read_timeout: 10000
agave_page_length: 5000
agave_oauth_refresh_window: 5
agave_client_key:
agave_client_secret:

amqp_broker_host: some.server5.at.a.place
amqp_broker_port: 5672
amqp_password: xxxx
amqp_user: guest
amqp_exchange: de
amqp_condor_events_exchange_routing_key: condor.events.renci
amqp_condor_events_queue_name: condor_events_renci


amqp_de_exchange:
amqp_de_exchange_durable: true
amqp_de_exchange_auto_delete: false
amqp_condor_events_exchange: condor_events
amqp_condor_events_exchange_type: fanout
amqp_condor_events_exchange_durable: true
amqp_condor_events_exchange_routing_key:
amqp_condor_events_queue_name:
amqp_condor_events_exchange_auto_delete: false
amqp_irods_exchange: irods
amqp_irods_exchange_type: topic
amqp_irods_exchange_durable: true
amqp_irods_exchange_auto_delete: false
amqp_irods_queue_routing_key: "data-object.#"
amqp_irods_message_auto_ack: true
amqp_irods_connection_health_check_interval: 5000


anon_files_base_url: "{{services_host}}"
anon_files_port: 5000


anon_files_proxy_url: "{{services_host}}"
anon_files_anon_user: anonymous
anon_files_log_file: /home/iplant/logs/anon-files.log
anon_files:
  service_name: anon-files.service
  service_name_short: anon-files
  service_description: anon-files service
  port: "{{anon_files_port}}"
  image_name: anon-files
  log_driver: "{{ docker.log_driver }}"
  container_name: anon-files
  properties_file: anon-files.properties
  log_file: anon-files-docker.log


belphegor_base: https://{{ui_host}}/belphegor
# cas_base: https://{{cas_host}}/cas
cas_base: https://{{cas_host}}:8443/cas
cas_uid_domain:
cas_group_attribute: entitlement


clockwork:
  service_name: clockwork.service
  service_name_short: clockwork
  service_description: clockwork service
  image_name: clockwork
  container_name: clockwork
  properties_file: clockwork.properties
  log_file: clockwork-docker.log


condor_submission_ip_range: 172.25.0.0/16
condor_allow_write: "{{ condor_submission_ip_range }}"
condor:
  host: some.server4.at.a.place
  admin: grid@example.org
  collector_name: "{{ environment_name }} pool"
  flock_to:
  filesystem_domain: example.org
  uid_domain: example.org
  allow_write: "{{ condor_allow_write }}"
  allow_read: "{{ condor_allow_write }}"
  cred_dir: /var/cred_dir


condor_log_monitor_event_log: /var/log/condor/event_log
condor_log_monitor:
  service_name: condor-log-monitor.service
  service_name_short: condor-log-monitor
  service_description: CLM; Condor log monitor
  image_name: jex-events
  container_name: clm
  properties_file: jex-events.properties
  log_file: condor-log-monitor-docker.log


## iPlant data container
data_container:
  unc_remote_registry: diceunc
  image_name: test
  container_name: iplant_data
  service_name: iplant-data.service
  service_name_short: iplant-data
  service_description: The iPlant Discovery Environment data container
  ssl:
    cert: "{{ nginx_ssl.cert }}"
    key: "{{ nginx_ssl.cert_key }}"
    gd_bundle_crt: /etc/ssl/gd_bundle.crt
  keystore:
    path: /etc/ssl/example.pkcs12
    password:
    type: pkcs12

data_info_host: "{{services_host}}"
data_info_port: 5001

data_info:
  service_name: data-info.service
  service_name_short: data-info
  service_description: data-info service
  port: "{{ data_info_port }}"
  image_name: data-info
  container_name: data-info
  properties_file: data-info.properties
  log_file: data-info-docker.log

de_base: https://{{ui_host}}/de

## App Settings
de:
  service_name: de-ui.service
  service_name_short: ui
  service_description: DE UI; iPlant Discovery Environment user interface
  image_name: de-ui
  container_name: de_ui
  log_driver: "{{ docker.log_driver }}"
  log_file: de-ui.log
  http_server:
    service_name: de-ui-nginx.service
    service_name_short: de-ui-nginx
    service_description: DE UI nginx
    image_name: nginx-ssl
    container_name: de_ui_nginx
    log_driver: "{{ docker.log_driver }}"
    log_file: nginx-de-ui.log
    ssl:
      server_name: "{{ nginx_ssl.server_name }}"
      cert: "{{ nginx_ssl.cert }}"
      cert_key: "{{ nginx_ssl.cert_key }}"
      insecure_redirects:
        - server_name: "{{ nginx_ssl.server_name }}"
          return: "https://$host$request_uri"
#      redirects:
#        - server_name: "~^(?<basename>[^.]+)[.]example[.]com$"

admin_groups:

app_version_name: Phthalo
app_version: 2.2.0

cas_no_logout_url: "{{cas_base}}"
cas_app_list: all iPlant applications

coge_base_url: https://genomevolution.org/coge/api/v1
coge_data_folder_name: coge_data
coge_user: coge

de_version: "{{ app_version }}"#          return: "https://$basename.example.org$request_uri"
#          ssl_certificate: "/etc/ssl/example.com.crt"
#          ssl_certificate_key: "/etc/ssl/example.com.key"




dewey_listen_port: 5002

db_user: de
db_password: blah
db_host: some.server3.at.a.place
db_port: 5432
db_name: de
db_admin: postgres
db_admin_password: blah
db_driver: org.postgresql.Driver
db_vendor: postgresql
db_allowed_IPv4_remote: 172.0.0.0/8
#  - "X.X.X.X/XX"


dewey:
  service_name: dewey.service
  service_name_short: dewey
  service_description: dewey service
  image_name: dewey
  container_name: dewey
  properties_file: dewey.properties
  log_file: dewey-docker.log


donkey_host: "{{services_host}}"
donkey_port: 5003
donkey_base: http://{{ donkey_host }}:{{ donkey.port }}
donkey:
  service_name: donkey.service
  service_name_short: donkey
  service_description: donkey service
  port: "{{donkey_port}}"
  image_name: donkey
  container_name: donkey
  properties_file: donkey.properties
  log_file: donkey-docker.log

de_feedback_to_addr: xxxx@unc.edu
de_mail_from_addr: "{{ de_feedback_to_addr }}"
de_mail_to_addr: "{{ de_feedback_to_addr }}"

elk_host: some.server4.at.a.place

es_base: "http://{{ es_host }}:{{ es_port }}"
es_host: some.server4.at.a.place
es_port:  9200
es_scroll_size: 1000

email_smtp_from_address: "noreply@renci-de.org"
email_port: 5013
email_host: "{{services_host}}"

# environment_name: dfc-test
environment_name: something

fs_max_paths_in_request: 1000

exim:
  service_name: exim-sender.service
  service_name_short: exim-sender
  service_description: exim-sender service
  image_name: exim-sender
  container_name: exim
  log_file: exim-docker.log

gpg_home_dir:

group_config: de

icat_host: dfc-test-irods1.at.a.place
icat_port: 5432
# user for direct reads
icat_user: icat_reader
# password for direct reads
icat_password: blah
icat_db: ICAT
# irods icat user
icat_irods_user: irods
# irods icat pass
irods_icat_password: blah
# default resource name
irods_default_resource: demoResc


infosquito_notify_enabled: true
infosquito_notify_count: 10000
infosquito_retry_interval: 900
infosquito:
  service_name: infosquito.service
  service_name_short: infosquito
  service_description: infosquito service
  image_name: infosquito
  container_name: infosquito
  properties_file: infosquito.properties
  log_file: infosquito-docker.log

info_typer:
  service_name: info-typer.service
  service_name_short: info-typer
  service_description: info-typer service
  image_name: info-typer
  container_name: info-typer
  properties_file: info-typer.properties
  log_file: info-typer-docker.log


iplant_groups_host: some.server3.at.a.place
iplant_groups_port: 80
iplant_groups:
  service_name: iplant-groups.service
  service_name_short: iplant-groups
  service_description: iplant-groups service
  host: "{{ iplant_groups_host }}"
  port: "{{ iplant_groups_port }}"
  base_url: "http://{{ iplant_groups_host }}:{{ iplant_groups_port }}"
  image_name: iplant-groups
  container_name: iplant-groups
  properties_file: iplant-groups.properties
  log_file: iplant-groups-docker.log
  grouper:
    username: "{{ grouper.admin.user }}"
    password: "{{ grouper.admin.pass }}"
    api_version: "v2_2_000"
    base_url: "{{ grouper.ws.base_url }}"


irods_host: dfc-test-irods1.at.a.place
irods_port: 1247
irods_user: rods
irods_password: blah
irods_zone: dfc1
irods_home: /{{ irods_zone }}/home
irods_default_resource: ""
irods_admins: "rodsadmin"
irods_admin_users: "{{ irods_user }},{{ irods_admins }}"
irods_bad_chars: \u0060\u0027\u000A\u0009

email_smtp_host: 127.0.0.1
email_smtp_from_address:
email_host: bogus.email.host
email_base: http://{{ email_host }}:{{ iplant_email.port }}
iplant_email:
  service_name: iplant-email.service
  service_name_short: iplant-email
  service_description: iPlant Email service
  port: 587
  image_name: iplant-email
  container_name: iplant-email
  properties_file: iplant-email.properties
  log_file: iplant-email-docker.log



jwt:
  signing_key:
    private: "{{ global_config_dir }}/crypto/private-key.pem"
    public: "{{ global_config_dir }}/crypto/public-key.pem"
    password: blah
    algorithm: "rs256"
  accepted_keys:
    dir: "{{ global_config_dir }}/crypto/accepted_keys"
  validity_window:
    end: 300
  wso2:
    header: x-jwt-assertion-iplant-org


grouper:
  service_name: iplant-grouper.service
  service_name_short: iplant-grouper
  service_description: Grouper UI and Web Services
  image_name: iplant-grouper
  container_name: iplant-grouper
  log_driver: "{{ docker.log_driver }}"
  max_heap_size: 2048M
  max_perm_size: 256M
  admin:
    user: grouper
    pass: grouper
  api:
    env_name: de
  container_name: grouper
  db:
    url:
    user:
    pass:
  http_server:
    service_name: grouper-nginx.service
    service_name_short: grouper-nginx
    service_description: Grouper nginx
    image_name: "{{ de.http_server.image_name }}"
    container_name: grouper-nginx
    log_driver: "{{ docker.log_driver }}"
    ssl:
      servers:
        - server_name: "{{ nginx_ssl.server_name }}"
          ssl_certificate: "{{ nginx_ssl.cert }}"
          ssl_certificate_key: "{{ nginx_ssl.cert_key }}"
      insecure_redirects:
        - server_name: "{{ nginx_ssl.server_name }}"
          return: "https://$host$request_uri"
  subject_source:
    id:
    name:
    url:
    auth_type:
    principal:
    credentials:
  ui:
    base_url:
  ws:
    base_url:


jex_host: "{{services_host}}"
jex_port: 5004
jex_nfs_base: /condor/scratch
jex_events: http://{{services_host}}:{{jex_events_listen_port}}/
jexdb_host: "{{db_host}}"
jexdb_user: jex_user
jexdb_password: "{{db_password}}"
jex_events_listen_port: :5005
jex_events_event_url: http://{{services_host}}:{{donkey_port}}/callbacks/de-job

jex_base: http://{{ jex_host }}:{{ jex_port }}
jex_batch_group: batch_processing
jex_icommands_path: /usr/local/icommands/:/usr/local/bin/:/usr/bin/
jex_request_disk: 0

# Jex does not actually have a container. The container name is how most syslog entries
# are identified. See rsyslog-config role.
jex:
  service_name: jex.service
  service_name_short: jex
  log_file: jex/jex.log
  container_name: jex

jexdb_driver: "{{db_driver}}"
jexdb_db: jex
jexdb_password: "{{db_password}}"
jexdb_port: "{{db_port}}"
jexdb_vendor: "{{db_vendor}}"

# port 5015 added by Lisa
jex_events_event_url:
jexevents:
  service_name: jex-events.service
  service_name_short: jex-events
  service_description: jex events service
  port: 5015
  image_name: jex-events
  container_name: jex-events
  properties_file: jex-events.properties
  log_file: jex-events-docker.log

job_status_poll_interval: 15

kifshare_external_url: https://{{ui_host}}/d

kifshare_de_url: \{\{url\}\}/d/\{\{ticket-id\}\}/\{\{filename\}\}
kifshare_mode: prod
kifshare_download_buffer_size: 100
kifshare:
  service_name: kifshare.service
  service_name_short: kifshare
  service_description: kifshare service
  port: 5006
  image_name: kifshare
  container_name: kifshare
  properties_file: kifshare.properties
  log_file: kifshare-docker.log


logstash_forwarder:
  service_description: logstash forwarder service
  service_name: logstash-forwarder.service
  service_name_short: logstash-forwarder
  image_name: willdurand/logstash-forwarder
  container_name: logstash-fowarder


max_edit_file_size: 2147483647


metadactyl_host: "{{services_host}}"
metadactyl_port: 5007

metadactyl_base: "http://{{ metadactyl_host }}:{{ metadactyl.port }}"

metadactyl_out_dir: analyses
metadactyl_path_list_max_paths: 16
metadactyl_path_list_max_size: 1048576

metadactyl_beta_category: 5401bd14-6c14-4470-aedd-57b47ea1b979
metadactyl_user_root: Workspace
metadactyl_user_subs: "[\"Apps under development\",\"Favorite Apps\"]"
metadactyl_trash_category: Trash
metadactyl:
  service_name: metadactyl.service
  service_name_short: metadactyl
  service_description: metadactyl service
  port: "{{metadactyl_port}}"
  image_name: metadactyl
  container_name: metadactyl
  properties_file: metadactyl.properties
  log_file: metadactyl-docker.log



metadata_db_driver: "{{ db_driver }}"
metadata_db_vendor: "{{ db_vendor }}"
metadata_db_host: "{{ db_host }}"
metadata_db_port: "{{ db_port }}"
metadata_db_user: metadata_db
metadata_db_password: "{{ db_password }}"
metadata_db_name: metadata
metadata_db_admin: "{{ db_admin }}"
metadata_db_admin_password: "{{ db_admin_password }}"
metadata:
  service_name: metadata.service
  service_name_short: metadata
  service_description: metadata service
  port: 5016
  image_name: metadata
  container_name: metadata
  properties_file: metadata.properties
  log_file: metadata-docker.log

metadata_host: "{{ services_host }}"


monkey:
  service_name: monkey.service
  service_name_short: monkey
  service_description: monkey service
  image_name: monkey
  container_name: monkey
  properties_file: monkey.properties
  log_file: monkey-docker.log

notification_clean_start: "1:45:00"
notification_clean_age: 90
notification_clean_enable: "true"
notification_db_driver: "{{ db_driver }}"
notification_db_vendor: "{{ db_vendor }}"
notification_db_port: "{{ db_port }}"
notification_db_host: "{{ db_host }}"
notification_db_name: notifications
notification_db_password: "{{ db_password }}"
notification_db_user: notification_user
notification_db_admin: "{{ db_admin }}"
notification_db_admin_password: "{{ db_admin_password }}"


notificationagent_base: "http://{{ notificationagent_host }}:{{ notificationagent.port }}"
notificationagent_host: "{{notificationagent_host}}"
notificationagent:
  service_name: notification-agent.service
  service_name_short: notificationagent
  service_description: notification agent service
  port: 65533
  image_name: notificationagent
  container_name: notificationagent
  properties_file: notificationagent.properties
  log_file: notificationagent-docker.log

nginx_ssl:
  server_name: some.server1.at.a.place
  cert: /etc/iplant/ssl/iplant.crt
  cert_key: /etc/iplant/ssl/iplant.key
# server_name: "~^[^.]+[.]example[.]org$"
# cert: "/etc/ssl/example.crt"
# cert_key: "/etc/ssl/example.key"

nibblonian_perms_filter:

notificationagent_host: "{{services_host}}"
notificationagent_port: 5008

path_list_file_identifier: "# application/vnd.de.path-list+csv; version=1"
path_list_info_type: ht-analysis-path-list

pgp_keyring_path: "{{ gpg_home_dir }}/secring.gpg"
pgp_key_password:

saved_searches_host: "{{services_host}}"
saved_searches_port: 5009

saved_searches_log_file: /home/iplant/logs/saved-searches.log
saved_searches:
  service_name: saved-searches.service
  service_name_short: saved-searches
  service_description: saved searches services
  port: "{{ saved_searches_port }}"
  image_name: saved-searches
  container_name: saved-searches
  properties_file: saved-searches.properties
  log_file: saved-searches-docker.log

search_default_limit: 200


tree_parser_base: http://bogus/parseTree

tree_urls_host: "{{services_host}}"
tree_urls_port: 5010

tree_urls_log_file: /home/iplant/logs/tree-urls.log
tree_urls_cleanup_age: 30
tree_urls_cleanup_start: "1:30:00"
tree_urls_cleanup_enable: "true"
tree_urls_avu: tree-urls
tree_urls:
  service_name: tree-urls.service
  service_name_short: tree-urls
  service_description: Tree urls service
  port: "{{ tree_urls_port }}"
  image_name: tree-urls
  container_name: tree-urls
  properties_file: tree-urls.properties
  log_file: tree-urls-docker.log


user_info_base:
user_info_client_key:
user_info_client_secret:

user_preferences_host: "{{services_host}}"
user_preferences_port: 5011

user_preferences_log_file: /home/iplant/logs/user-preferences.log
user_preferences:
  service_name: user-preferences.service
  service_name_short: user-preferences
  service_description: user preferences service
  port: "{{ user_preferences_port }}"
  image_name: user-preferences
  container_name: user-preferences
  properties_file: user-preferences.properties
  log_file: user-preferences-docker.log


user_sessions_port: 5012

user_sessions_host: "{{services_host}}"
user_sessions_log_file: /home/iplant/logs/user-sessions.log
user_sessions:
  service_name: user-sessions.service
  service_name_short: user-sessions
  service_description: user sessions service
  port: "{{ user_sessions_port }}"
  image_name: user-sessions
  container_name: user-sessions
  properties_file: user-sessions.properties
  log_file: user-sessions-docker.log

# default vars file for postgresql
pg_version: 9.4
pg_encoding: 'UTF-8'
pg_locale: 'en_US.UTF-8'
pg_recreate_cluster: true


elk:
  conf_dir: "{{de_config_dir}}/elk"
  logstash:
    port: 5000
    container_name: elklogstash
    service_name: elk-logstash.service
    service_name_short: elk-logstash
    service_description: ELK logstash
    image_name: de-logstash
    log_file: elk-logstash-docker.log
  data:
    container_name: elkdata
    service_name: elk-data.service
    service_name_short: elk-data
    service_description: ELK data container
    image_name: busybox
  elasticsearch:
    port: 9200
    container_name: elkelasticsearch
    service_name: elk-elasticsearch.service
    service_name_short: elk-elasticsearch
    service_description: ELK elasticsearch
    image_name: elasticsearch
    heap_size: "3g"
    cluster_name: "de-elk-dev"
    log_file: elk-elasticsearch-docker.log
  kibana:
    port: 5601
    container_name: elkkibana
    service_name: elk-kibana.service
    service_name_short: elk-kibana
    service_description: ELK kibana
    version: 4.2
    image_name: "kibana:4.2"
    log_file: elk-kibana-docker.log

logging:
  dir: /var/log/de
  conf_dir: "{{de_config_dir}}/logging"


systemd:
  syslogFacility: local6
  services:
          - "{{anon_files}}"
          - "{{clockwork}}"
          - "{{condor_log_monitor}}"
          - "{{data_info}}"
          - "{{de.http_server}}"
          - "{{de}}"
          - "{{dewey}}"
          - "{{donkey}}"
          - "{{elk.elasticsearch}}"
          - "{{elk.kibana}}"
          - "{{elk.logstash}}"
          - "{{exim}}"
          - "{{infosquito}}"
          - "{{info_typer}}"
          - "{{iplant_email}}"
          - "{{iplant_groups}}"
          - "{{jex}}"
          - "{{jexevents}}"
          - "{{kifshare}}"
          - "{{metadactyl}}"
          - "{{metadata}}"
          - "{{monkey}}"
          - "{{notificationagent}}"
          - "{{saved_searches}}"
          - "{{tree_urls}}"
          - "{{user_preferences}}"
          - "{{user_sessions}}


